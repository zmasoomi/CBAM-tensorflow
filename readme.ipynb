{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zmasoomi/CBAM-tensorflow/blob/master/readme.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7faf3407",
      "metadata": {
        "id": "7faf3407"
      },
      "source": [
        "the aim of this study is the segmentation of MRI Image for Multipl sclerosis lesions. this project is a part of the main project to be defined for sevierity of lesions. Despite many studies that have worked on this topic and published software and algorithms, there are still some limitations in this process that leads to incorrect measurement of lesions. Some of the developed software is based on manual segmentation by user which could lead to poor reproducibility of the final results. Other algorithms use automatic segmentation pipelines that have more reproducibility in their results but less accurate in detecting some lesions (e.g. cortical lesions). \n",
        "\n",
        "In this study, 400 participants with relapsing-remitting multiple sclerosis (RRMS) after ethics approval were scanned using multiple 1.5 tesla MRI machines. All participants underwent a medical examination in order to make sure they didn’t have relapses in the last 6 months and also didn’t undergo steroid medication in the last 6 months. Scan protocol contains 3D FLAIR and T1 weighted images with isotropic 1 mm resolution. Same imaging parameters were used in all MRI scanners in order to maintain image quality, SNR, and CNR for all participants.\n",
        "\n",
        "Segentation has been done by deep learning using nibabel, keras, tensorflow and open_cv. to start the modelling, preprocess is a crucial step because of reinforce th image and correct all allignments and remove noise to have a precise segmentation.\n",
        "one step after allignment is removing skull in order to do brain extraction then to extract binary mask as a final step in preprocessing.\n",
        "\n",
        "For the modelling part, Unet with resnet50 as backbone has been used. the reference for this project is calibrated according to article which is mentioned in my project at the end of the codes. \n",
        "the result has been evaluated by dice coefficient(mean IOU for comaparing). inspite of the acuaracy as 1, the dice coefficient is low. because of mask background which is more than 95% black, so in comparing pixel by pixel, accuracy is really near to 1, thugh for region covering, due to have small spot which is the expected segmnetation as a correct result, is low. \n",
        "in order to improve this result, this project is going to progress. I will try to update this project with the better result in near future.\n",
        "Next update would be one of the pivotal step as a preprocessing is image augmentation.\n",
        "\n",
        "I appreciate to have any idea ar any correction in model and codes letting me know about.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e51cd46d",
      "metadata": {
        "id": "e51cd46d"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}